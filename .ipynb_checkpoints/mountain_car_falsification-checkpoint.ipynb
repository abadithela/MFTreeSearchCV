{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC,SVR\n",
    "import os\n",
    "import sys\n",
    "from MFTreeSearchCV.MFTreeSearchCV import *\n",
    "from mf.mf_func import *\n",
    "import scipy as sp\n",
    "import scipy.io as scio\n",
    "import pickle as pkl\n",
    "from multipolyfit.multipolyfit import multipolyfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model \n",
    "import matlab\n",
    "import matlab.engine as meng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MATLAB through MATLAB Engine API\n",
    "eng = meng.connect_matlab()\n",
    "eng.cd('../mountain_car/')# Location of simulator\n",
    "\n",
    "# setup:\n",
    "meng.find_matlab()\n",
    "eng.setup_mc(nargout=0)\n",
    "eng.query_simulator(-0.52, -0.0297) # Sanity check, Answer should be around -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data: All of it\n",
    "RHO_mat = scio.loadmat('data/mountain_car/RHO.mat')\n",
    "X0_mat = scio.loadmat('data/mountain_car/X0.mat')\n",
    "V0_mat = scio.loadmat('data/mountain_car/V0.mat')\n",
    "\n",
    "RHO = RHO_mat['RHO']\n",
    "X0 = X0_mat['X0']\n",
    "V0 = V0_mat['V0']\n",
    "\n",
    "# Data for violations:\n",
    "rho_r_mat = scio.loadmat('data/mountain_car/rho_r.mat')\n",
    "xr_mat = scio.loadmat('data/mountain_car/xr.mat')\n",
    "vr_mat = scio.loadmat('data/mountain_car/vr.mat')\n",
    "\n",
    "rho_r = rho_r_mat['rho_r']\n",
    "xr = xr_mat['xr']\n",
    "vr = vr_mat['vr']\n",
    "\n",
    "# Data for successes:\n",
    "rho_g_mat = scio.loadmat('data/mountain_car/rho_g.mat')\n",
    "xg_mat = scio.loadmat('data/mountain_car/xg.mat')\n",
    "vg_mat = scio.loadmat('data/mountain_car/vg.mat')\n",
    "\n",
    "rho_g = rho_g_mat['rho_g']\n",
    "xg = xg_mat['xg']\n",
    "vg = vg_mat['vg']\n",
    "\n",
    "Nsamples = len(X0.T)\n",
    "assert(Nsamples == len(V0.T))\n",
    "assert(Nsamples*Nsamples == len(RHO[:,0]))\n",
    "print(Nsamples)\n",
    "DEG = 4 # Degree of the polynomial that is being fit to the data\n",
    "SET_APPROX = 0\n",
    "disc_z = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # discretizing z\n",
    "step = 0.1\n",
    "ndisc = len(disc_z)\n",
    "print(ndisc)\n",
    "fidel_dim = 2\n",
    "\n",
    "# Regressors:\n",
    "classifiers = [\n",
    "    SVR(),\n",
    "    linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "    linear_model.LassoLars(),\n",
    "    linear_model.ARDRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.TheilSenRegressor(),\n",
    "    linear_model.LinearRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing function approximations using polyfit:\n",
    "fname_approx_polyfit = \"Approximations/multipolyfit_approx.pkl\"\n",
    "fname_approx_logreg = \"Approximations/logreg_approx.pkl\"\n",
    "\n",
    "rsv_approxs_polyfit = dict() # List containing poly-fit functions that approximate the robust satisfaction value\n",
    "rsv_approxs_logreg = dict() # List containing poly-fit functions that approximate the robust satisfaction value\n",
    "    \n",
    "def construct_approx_polyfit():\n",
    "    for x0_idx in disc_z:\n",
    "        for v0_idx in disc_z: \n",
    "            idx = ndisc*(x0_idx*10 - 1) + v0_idx*10\n",
    "            x0_num = int((x0_idx + step)*Nsamples)\n",
    "            v0_num = int((v0_idx + step)*Nsamples)\n",
    "            assert(x0_num <= Nsamples)\n",
    "            if(v0_num > Nsamples):\n",
    "                print(v0_num)\n",
    "                assert(v0_num <= Nsamples)\n",
    "            x0_indices = np.random.choice(Nsamples, x0_num, replace=False)\n",
    "            v0_indices = np.random.choice(Nsamples, v0_num, replace=False)\n",
    "            rho0_indices = [Nsamples*(x_ii-1)+v_ii  for x_ii in x0_indices for v_ii in v0_indices]\n",
    "            x0_samples = [X0.T[ii,0] for ii in x0_indices] # Indices for x0 from the original data\n",
    "            v0_samples = [V0.T[ii,0] for ii in v0_indices] # Indices for v0 from the original data\n",
    "            assert(len(rho0_indices) == len(x0_indices)*len(v0_indices))\n",
    "            x0 = np.array([[xi, vi] for xi in x0_samples for vi in v0_samples]) # Combined x0 and v0\n",
    "            rho = np.array([RHO[ii,0] for ii in rho0_indices])\n",
    "            assert(len(x0) == len(rho))\n",
    "            \n",
    "            model = multipolyfit(x0, rho, DEG, model_out = True)\n",
    "            print(model)\n",
    "            rsv_approxs_polyfit[idx] = model\n",
    "    # pkl.dump(rsv_approxs, open(fname_approx_polyfit, \"wb\"))\n",
    "\n",
    "zidx = lambda z1,z2: ndisc*(z1*10)+z2*10\n",
    "# Constructing function approximations via tree search:\n",
    "n_x0_samples = []\n",
    "n_v0_samples = []\n",
    "def construct_approx_logreg():\n",
    "    for x0_idx in disc_z:\n",
    "        for v0_idx in disc_z:\n",
    "            idx = zidx(x0_idx, v0_idx)\n",
    "            x0_num = int((x0_idx + step)*Nsamples)\n",
    "            v0_num = int((v0_idx + step)*Nsamples)\n",
    "            assert(x0_num <= Nsamples)\n",
    "            if(v0_num > Nsamples):\n",
    "                print(v0_num)\n",
    "                assert(v0_num <= Nsamples)\n",
    "            x0_indices = np.random.choice(Nsamples, x0_num, replace=False)\n",
    "            v0_indices = np.random.choice(Nsamples, v0_num, replace=False)\n",
    "            rho0_indices = [Nsamples*(x_ii-1)+v_ii  for x_ii in x0_indices for v_ii in v0_indices]\n",
    "            x0_samples = [X0.T[ii,0] for ii in x0_indices] # Indices for x0 from the original data\n",
    "            v0_samples = [V0.T[ii,0] for ii in v0_indices] # Indices for v0 from the original data\n",
    "            n_x0_samples.append(len(x0_samples))\n",
    "            n_v0_samples.append(len(v0_samples))\n",
    "            assert(len(rho0_indices) == len(x0_indices)*len(v0_indices))\n",
    "            x0 = np.array([[xi, vi] for xi in x0_samples for vi in v0_samples]) # Combined x0 and v0\n",
    "            rho = np.array([RHO[ii,0] for ii in rho0_indices])\n",
    "            assert(len(x0) == len(rho))\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(x0, rho)\n",
    "            reg = linear_model.SGDRegressor()\n",
    "            reg.fit(X_train, y_train)\n",
    "            print(reg.score(X_test, y_test))\n",
    "            rsv_approxs_logreg[int(idx)] = reg\n",
    "    # pkl.dump(rsv_approxs, open(fname_approx_logreg, \"wb\"))\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check:\n",
    "xopt = [-0.52, -0.0297]\n",
    "classif = classifiers.copy()\n",
    "xopt_arr = np.array(xopt).reshape(1,-1)\n",
    "x0_idx = 0.1\n",
    "v0_idx = 0.1\n",
    "rsv_approxs_logreg = dict()\n",
    "idx = zidx(x0_idx, v0_idx)\n",
    "print(int(idx))\n",
    "x0_num = int((x0_idx + step)*Nsamples)\n",
    "v0_num = int((v0_idx + step)*Nsamples)\n",
    "assert(x0_num <= Nsamples)\n",
    "if(v0_num > Nsamples):\n",
    "    print(v0_num)\n",
    "    assert(v0_num <= Nsamples)\n",
    "x0_indices = np.random.choice(Nsamples, x0_num, replace=False)\n",
    "v0_indices = np.random.choice(Nsamples, v0_num, replace=False)\n",
    "rho0_indices = [Nsamples*(x_ii-1)+v_ii  for x_ii in x0_indices for v_ii in v0_indices]\n",
    "x0_samples = [X0.T[ii,0] for ii in x0_indices] # Indices for x0 from the original data\n",
    "v0_samples = [V0.T[ii,0] for ii in v0_indices] # Indices for v0 from the original data\n",
    "assert(len(rho0_indices) == len(x0_indices)*len(v0_indices))\n",
    "x0 = np.array([[xi, vi] for xi in x0_samples for vi in v0_samples]) # Combined x0 and v0\n",
    "rho = np.array([RHO[ii,0] for ii in rho0_indices])\n",
    "assert(len(x0) == len(rho))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x0, rho)\n",
    "print(len(X_train))\n",
    "reg1 = classif[-1]\n",
    "reg1.fit(X_train, y_train)\n",
    "print(reg1.score(X_test, y_test))\n",
    "rsv_approxs_logreg[int(idx)] = reg1\n",
    "print(reg1.predict(xopt_arr))\n",
    "\n",
    "\n",
    "# ssecond one:\n",
    "x0_idx = 0.9\n",
    "v0_idx = 0.5\n",
    "classif = classifiers.copy()\n",
    "idx = zidx(x0_idx, v0_idx)\n",
    "print(int(idx))\n",
    "x0_num = int((x0_idx + step)*Nsamples)\n",
    "v0_num = int((v0_idx + step)*Nsamples)\n",
    "assert(x0_num <= Nsamples)\n",
    "if(v0_num > Nsamples):\n",
    "    print(v0_num)\n",
    "    assert(v0_num <= Nsamples)\n",
    "x0_indices = np.random.choice(Nsamples, x0_num, replace=False)\n",
    "v0_indices = np.random.choice(Nsamples, v0_num, replace=False)\n",
    "rho0_indices = [Nsamples*(x_ii-1)+v_ii  for x_ii in x0_indices for v_ii in v0_indices]\n",
    "x0_samples = [X0.T[ii,0] for ii in x0_indices] # Indices for x0 from the original data\n",
    "v0_samples = [V0.T[ii,0] for ii in v0_indices] # Indices for v0 from the original data\n",
    "assert(len(rho0_indices) == len(x0_indices)*len(v0_indices))\n",
    "x0 = np.array([[xi, vi] for xi in x0_samples for vi in v0_samples]) # Combined x0 and v0\n",
    "rho = np.array([RHO[ii,0] for ii in rho0_indices])\n",
    "assert(len(x0) == len(rho))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x0, rho)\n",
    "print(len(X_train))\n",
    "reg2 = classif[-1]\n",
    "reg2.fit(X_train, y_train)\n",
    "print(reg2.score(X_test, y_test))\n",
    "rsv_approxs_logreg[int(idx)] = reg2\n",
    "\n",
    "\n",
    "print(reg2.predict(xopt_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling functions to construct the models:\n",
    "construct_approx_polyfit()\n",
    "construct_approx_logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing function approximations of the robust satisfaction value at multiple fidelities:\n",
    "# Use the polyfit function to create approximations:\n",
    "# Using discrete fidelity bounds of 1-D fidelity: z = [0.0 0.1, 0.2, 0.3, ...., 0.9]. z \\in [0,0.1) is evaluated at fidelity 0.0. \n",
    "# z = 1 is fidelity at ground truth value, and we run the simulator for that. not given with the approximations\n",
    "def find_z_closest(z, fidel_dim):\n",
    "    assert(len(z)==fidel_dim)\n",
    "    z1 = 0 # Normalized fidelity for x0\n",
    "    z2 = 0 # Normalized fidelity for  v0\n",
    "    for ii in range(1, len(disc_z)):\n",
    "        if(z[0]>=disc_z[ii-1] and z[0]<disc_z[ii]):\n",
    "            z1 = disc_z[ii-1]\n",
    "        if(z[1]>=disc_z[ii-1] and z[1]<disc_z[ii]):\n",
    "            z2 = disc_z[ii-1]\n",
    "    if(z[0] == 0.9):\n",
    "        z1 = 0.9\n",
    "    if(z[1] == 0.9):\n",
    "        z2 = 0.9\n",
    "    return z1, z2\n",
    "\n",
    "def get_approx_polyfit(approx_id):\n",
    "    rsv_approxs = rsv_approxs_polyfit.copy()\n",
    "    return rsv_approxs[approx_id]\n",
    "\n",
    "def get_approx_logreg(approx_id):\n",
    "    rsv_approxs = rsv_approxs_logreg.copy()\n",
    "    return rsv_approxs[approx_id]\n",
    "\n",
    "def retrieve_approximation(z, fidel_dim, approx_type):\n",
    "    z1, z2 = find_z_closest(z, fidel_dim)\n",
    "    if (z1 < 1):\n",
    "        z1_id = z1\n",
    "    if (z2 < 1):\n",
    "        z2_id = z2\n",
    "    approx_id = int(zidx(z1,z2))\n",
    "    # print(\"approx id: \"+str(approx_id))\n",
    "    if (approx_type == \"logreg\"):\n",
    "        approximation = get_approx_logreg(approx_id)\n",
    "    if (approx_type == \"polyfit\"):\n",
    "        approximation = get_approx_polyfit(approx_id)\n",
    "    return approximation\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high fidelity model\n",
    "def query_sim(x):\n",
    "    xarr = convert_to_arr_shape(x)\n",
    "    x0 = float(xarr[0,0])\n",
    "    v0 = float(xarr[0,1])\n",
    "    rsv = eng.query_simulator(x0, v0)\n",
    "    return -rsv\n",
    "def rsv_function(z,x, approx_type):\n",
    "    # \"\"\" Computes the rsv function. \"\"\"\n",
    "    func_computation = 0\n",
    "    if(approx_type == \"logreg\"):\n",
    "        func_computation = rsv_function_logreg(x,z)\n",
    "    if (approx_type == \"polyfit\"):\n",
    "        func_computation = rsv_function_polyfit(x,z)\n",
    "    return -func_computation\n",
    "\n",
    "def rsv_function_logreg(x, z):\n",
    "    #\"\"\" Alternative form for the rsv function. \"\"\"\n",
    "    z_arr = convert_to_arr_shape(z)\n",
    "    x_arr = convert_to_arr_shape(x)\n",
    "    approximation = retrieve_approximation(z_arr[0], fidel_dim, \"logreg\")\n",
    "    func_computation = approximation.predict(x_arr)\n",
    "    return func_computation\n",
    "\n",
    "def rsv_function_polyfit(x, z):\n",
    "    #\"\"\" Alternative form for the branin function. \"\"\"\n",
    "    approximation = retrieve_approximation(z, fidel_dim, \"polyfit\")\n",
    "    return approximation\n",
    "\n",
    "def get_mf_rsv_function(fidel_dim, approx_type):\n",
    "    #\"\"\" Returns the rsv function as a multifidelity function. \"\"\n",
    "    \n",
    "    def mf_rsv_obj(x, z):\n",
    "    #\"\"\" Wrapper for the MF rsv objective.\"\"\" \n",
    "        assert len(z) == fidel_dim\n",
    "        if (z[0]==1 or z[1]==1):\n",
    "            return query_sim(x)\n",
    "        else:\n",
    "            if approx_type == \"polyfit\":\n",
    "                return rsv_function(z,x,\"polyfit\")\n",
    "            else:\n",
    "                return rsv_function(z,x,\"logreg\")\n",
    "    \n",
    "    # Other data\n",
    "    opt_fidel = np.ones((fidel_dim)) # For now, exclude the ground truth\n",
    "    fidel_bounds = [[0, 1]] * fidel_dim\n",
    "    opt_pt = np.array([-0.52, -0.0297])\n",
    "    domain_bounds = [[-1, 0.6], [-0.42, 0.42]] # for x = [x0_bound, v0_bound]\n",
    "    return mf_rsv_obj, opt_pt, opt_fidel, fidel_bounds, domain_bounds\n",
    "\n",
    "# Function to get cost function:\n",
    "def _get_mf_cost_function(fidel_bounds, is_0_1):\n",
    "    \"\"\" Returns the cost function. fidel_bounds are the bounds for the fidelity space\n",
    "      and is_0_1 should be true if fidel_bounds is [0,1]^p. \"\"\"\n",
    "    fidel_dim = len(fidel_bounds)\n",
    "    if fidel_dim == 1:\n",
    "        fidel_powers = [2]\n",
    "    elif fidel_dim == 2:\n",
    "        fidel_powers = [3, 2]\n",
    "    elif fidel_dim == 3:\n",
    "        fidel_powers = [3, 2, 1.5]\n",
    "    else:\n",
    "        fidel_powers = [3] + list(np.linspace(2, 1.2, fidel_dim-1))\n",
    "    # Define the normalised\n",
    "    def _norm_cost_function(norm_z):\n",
    "    \"\"\" The cost function with normalised coordinates. \"\"\"\n",
    "        min_cost = 0.05\n",
    "        return min_cost + (1-min_cost) * np.power(norm_z, fidel_powers).sum()\n",
    "    \n",
    "    # Now return based on whether or not is_0_1\n",
    "    ret = (_norm_cost_function if is_0_1 else\n",
    "           lambda z: _norm_cost_function(map_to_cube(z, fidel_bounds)))\n",
    "    return ret\n",
    "\n",
    "# Function to convert to array that can be fed into regressor from list:\n",
    "def convert_to_arr_shape(opt_val):\n",
    "    opt_val_arr = np.array(opt_val).reshape(1,-1)\n",
    "    return opt_val_arr\n",
    "def get_mf_rsv_as_mfof(fidel_dim, approx_type):\n",
    "#\"\"\" Wrapper for get_mf_rsv_function which returns as a mfof. \"\"\"\n",
    "    mf_rsv_obj, opt_pt, opt_fidel, fidel_bounds, domain_bounds = get_mf_rsv_function(fidel_dim, approx_type)\n",
    "    fidel_cost_function = _get_mf_cost_function(fidel_bounds, True) # Figure out this line\n",
    "\n",
    "    opt_val = mf_rsv_obj(opt_fidel, opt_pt)\n",
    "    return MFOptFunction(mf_rsv_obj, fidel_cost_function, fidel_bounds, domain_bounds,\n",
    "                       opt_fidel, vectorised=False, opt_pt=opt_pt, opt_val=opt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing RSV function:\n",
    "fidel_dim = 2\n",
    "mf_rsv_obj, opt_pt, opt_fidel, fidel_bounds, domain_bounds = get_mf_rsv_function(fidel_dim, \"logreg\")\n",
    "z1 = [0.1, 0.1]\n",
    "x1 = [0.1, 0.2]\n",
    "z2 = [-0.5, -0.3]\n",
    "x2 = [0.1, 0.2]\n",
    "xopt = [-0.52, -0.0297]\n",
    "zopt = [1,1]\n",
    "\n",
    "# print(mf_rsv_obj(xopt, zopt)) # sanity check; should be 0.972\n",
    "ztest1 = [0.1, 0.1]\n",
    "zid1 = zidx(ztest1[0], ztest1[1])\n",
    "print(zid1)\n",
    "print(mf_rsv_obj(xopt, ztest1)) # \n",
    "ztest2 = [0.1, 0.9]\n",
    "print(mf_rsv_obj(xopt, ztest2)) # \n",
    "ztest3 = [0.9, 0.9]\n",
    "print(mf_rsv_obj(xopt, ztest3)) # \n",
    "\n",
    "rsv_approxs_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MF Optimization:\n",
    "mf_rsv_opt = get_mf_rsv_as_mfof(fidel_dim, \"logreg\")\n",
    "noise_var = 0.01\n",
    "sigma = np.sqrt(noise_var)\n",
    "\n",
    "# Running a single experiment:\n",
    "NUM_EXP = 1\n",
    "EXP_NAME = \"RSV_Mountain_Car\"\n",
    "def run_one_experiment(mfobject,nu,rho,times,sigma,C,t0,filename):\n",
    "    R = []\n",
    "    T = []\n",
    "    Xarr = []\n",
    "    for t in times:\n",
    "        budget = t*mfobject.opt_fidel_cost\n",
    "        t1 = time.time()\n",
    "        MP = MFPOO(mfobject=mfobject, nu_max=nu, rho_max=rho, total_budget=budget, sigma=sigma, C=C, mult=0.5, tol = 1e-3, Randomize = False, Auto = True, unit_cost=t0 )\n",
    "        MP.run_all_MFHOO()\n",
    "        X, E = MP.get_point()\n",
    "        t2 = time.time()\n",
    "\n",
    "        R = R + [E]\n",
    "        T = T + [MP.cost]\n",
    "        Xarr = Xarr + [X]\n",
    "    print(str(MP.cost) + ' : ' + str(E))\n",
    "    #print 'Total HOO Queries: ' + str(MP.t) \n",
    "    np.save(filename,R)\n",
    "    return np.array(R),np.array(T), np.array(Xarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -1\n",
    "b = 0.6\n",
    "c = -0.42\n",
    "d = 0.42\n",
    "rho_analysis = 0.25\n",
    "nu_analysis = 4*(b-a)**2 + 4*(d-c)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running experiments:\n",
    "# times = [10,20,50,75,100,150,175, 200]\n",
    "mfobject = get_noisy_mfof_from_mfof(mf_rsv_opt, noise_var)\n",
    "# mfobject = mf_rsv_opt\n",
    "times = [10]\n",
    "nu = nu_analysis\n",
    "rho = 0.95\n",
    "C = 0.1\n",
    "t0 = mfobject.opt_fidel_cost\n",
    "\n",
    "\n",
    "NT = str(time.time())\n",
    "print('Running Experiment 1: ')\n",
    "filename = 'MFHOO' + EXP_NAME + '_' + NT + '_' + '1.npy'\n",
    "R,T = run_one_experiment(mfobject,nu,rho,times,sigma,C,t0,filename)\n",
    "result = R\n",
    "\n",
    "print('Finished eXP 1')\n",
    "for i in range(1,NUM_EXP):\n",
    "    print('Running Experiment' + str(i+1) + ': ')\n",
    "    filename = 'MFHOO' + EXP_NAME + '_' + NT + '_' + str(i+1) + '.npy'\n",
    "    R,T, Xarr = run_one_experiment(mfobject,nu,rho,times,sigma,C,t0,filename)\n",
    "    result = np.vstack([result,R])\n",
    "\n",
    "mu = np.mean(result,axis = 0)\n",
    "std = np.std(result,axis = 0)\n",
    "result = mfobject.opt_val - mu\n",
    "\n",
    "filename = './data/mountain_car/MFHOO_' + EXP_NAME + '_' + NT + '_' + '.csv'\n",
    "dfdic = {}\n",
    "dfdic['Capital'] = np.array(times)\n",
    "dfdic['Value'] = result\n",
    "dfdic['Std'] = std\n",
    "df = pd.DataFrame(dfdic)\n",
    "df.to_csv(filename) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(dfdic, open('SGDRegressor_noise_nu_analysis_t_10', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mf.mf_func import NoisyMFOptFunction, plot_2d_function\n",
    "\n",
    "# def visualise_mfof(mfof):\n",
    "#     \"\"\" Visualises the mfof object. \"\"\"\n",
    "#     plot_func = mfof.eval_multiple\n",
    "#     _, ax, plt = plot_2d_function(plot_func,\n",
    "#                                np.array([mfof.fidel_bounds[0], mfof.domain_bounds[0]]),\n",
    "#                                x_label='fidel', y_label='domain')\n",
    "#     ax.scatter(mfof.opt_fidel, mfof.opt_pt, mfof.opt_val, c='r', s=100)\n",
    "#     plt.show()\n",
    "\n",
    "# visualise_mfof(mf_rsv_opt) # visualize mfof function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"MFHOORSV_Mountain_Car_1597098498.912148_1.npy\")\n",
    "T\n",
    "opt_val = mf_rsv_obj(opt_fidel, opt_pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the MATLAB engine:\n",
    "eng.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
